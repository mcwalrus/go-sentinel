// Package sentinel provides reliability handling and observability monitoring for Go applications.
// It wraps task execution with Prometheus metrics, observing errors, panic occurrences, retries,
// and timeouts â€” making critical routines safe, measurable, and reliable.
package sentinel

import (
	"context"
	"errors"
	"time"

	"github.com/prometheus/client_golang/prometheus"
)

type observerConfig struct {
	namespace       string
	subsystem       string
	description     string
	bucketDurations []float64
	constLabels     prometheus.Labels
	taskConfig      *TaskConfig
	recoverPanics   bool
}

// ObserverOption defines an configuration option for an Observer.
// Options are provided to [NewObserver] on setting up the Observer.
type ObserverOption func(*observerConfig)

// WithNamespace sets the Prometheus namespace for all metrics generated by this observer.
// For example, "myapp" results in metrics like "myapp_successes_total".
// If empty with subsystem, no namespace prefix is used.
func WithNamespace(namespace string) ObserverOption {
	return func(cfg *observerConfig) {
		cfg.namespace = namespace
	}
}

// WithSubsystem sets the Prometheus subsystem for all metrics generated by this observer.
// For example, "workers" results in metrics like "workers_successes_total".
// If empty with namespace, defaults to "sentinel" if not specified.
func WithSubsystem(subsystem string) ObserverOption {
	return func(cfg *observerConfig) {
		cfg.subsystem = subsystem
	}
}

// WithDescription sets the description used in the help text for generated metrics to
// describe what type of tasks are being observed. For example, "background processes"
// results in help text like: "Number of successes from observed background processes".
// Defaults to "tasks" if not specified.
func WithDescription(description string) ObserverOption {
	return func(cfg *observerConfig) {
		cfg.description = description
	}
}

// WithHistogramBuckets sets histogram bucket durations for the Observer.
// If not specified, no histogram metrics will be recorded or exported by the Observer.
// Each bucket duration is a float64 representing seconds where final buckets between 0 and math.Inf
// will be included after. Each recorded task duration is assigned within one of the specified buckets.
//
// Example usage:
//
//	observer := sentinel.NewObserver(sentinel.WithHistogramBuckets([]float64{0.05, 1, 5, 30, 600}))
//
// Please refer to [prometheus.HistogramOpts].Buckets for more information.
func WithHistogramBuckets(buckets []float64) ObserverOption {
	return func(cfg *observerConfig) {
		cfg.bucketDurations = buckets
	}
}

// WithConstLabels sets constant labels to exported metrics from the Observer.
// By default, no labels are attached. Please refer to [prometheus.Opts].ConstLabels
// for more information.
func WithConstLabels(labels prometheus.Labels) ObserverOption {
	return func(cfg *observerConfig) {
		cfg.constLabels = labels
	}
}

// WithDefaultTaskConfig sets the default [TaskConfig] for calls to [Observer.RunFunc].
// If not specified, a basic task configuration without retry attempts will be used.
func WithDefaultTaskConfig(taskConfig *TaskConfig) ObserverOption {
	return func(cfg *observerConfig) {
		cfg.taskConfig = taskConfig
	}
}

// WithPanicRecovery sets whether panics should be recovered and returned as errors.
// By default, when true panics are recovered and returned as [ErrPanicOccurred].
// Panic occurrences are always recorded in metrics regardless of this setting.
func WithPanicRecovery(recover bool) ObserverOption {
	return func(cfg *observerConfig) {
		cfg.recoverPanics = recover
	}
}

// Observer monitors and measures task executions, collecting Prometheus metrics
// for successes, failures, timeouts, panics, retries, and execution durations.
// It provides methods to execute tasks with various configuration options.
type Observer struct {
	cfg     observerConfig
	metrics *metrics
}

// NewObserver creates a new Observer instance with the specified options.
// The Observer will need to be registered with a Prometheus registry to expose metrics.
// Please refer to [Observer.MustRegister] and [Observer.Register] for more information.
//
// Example usage:
//
//	observer := sentinel.NewObserver() // Default configuration
//	observer := sentinel.NewObserver(sentinel.WithNamespace("myapp"))
//	observer := sentinel.NewObserver(
//	    sentinel.WithNamespace("myapp"),
//	    sentinel.WithSubsystem("workers"),
//	    sentinel.WithHistogramBuckets([]float64{0.05, 1, 5, 30, 600}),
//	)
func NewObserver(opts ...ObserverOption) *Observer {
	cfg := observerConfig{
		namespace:     "",
		subsystem:     "",
		description:   "tasks",
		recoverPanics: true,
	}

	// Apply options
	for _, opt := range opts {
		opt(&cfg)
	}

	// Apply defaults if not set
	if cfg.subsystem == "" && cfg.namespace == "" {
		cfg.subsystem = "sentinel"
	}
	if cfg.description == "" {
		cfg.description = "tasks"
	}
	if cfg.taskConfig == nil {
		cfg.taskConfig = &TaskConfig{}
	}

	return &Observer{
		cfg:     cfg,
		metrics: newMetrics(cfg),
	}
}

// Register registers all Observer metrics with the provided Prometheus registry.
// Use [Observer.MustRegister] if you want the program to panic on registration conflicts.
func (o *Observer) Register(registry prometheus.Registerer) error {
	return o.metrics.Register(registry)
}

// MustRegister registers all Observer metrics with the provided Prometheus registry.
// This method panics if any metric registration failures. Use [Observer.Register] if you prefer
// to handle registration errors gracefully.
func (o *Observer) MustRegister(registry prometheus.Registerer) {
	o.metrics.MustRegister(registry)
}

// Run executes a function with the specified task configuration and observes its execution.
// Any timeout specified through the task configuration will be ignored by the function.
func (o *Observer) Run(cfg TaskConfig, fn func() error) error {
	if o == nil || o.metrics == nil {
		panic("observer: not configured")
	}
	task := &implTask{
		cfg: cfg,
		fn: func(ctx context.Context) error {
			return fn() // ignore ctx
		},
	}
	return o.observe(task)
}

// Run executes a function with the specified task configuration and observes its execution.
// Any timeout specified through the task configuration will be set by the context passed to fn.
func (o *Observer) RunCtx(cfg TaskConfig, fn func(ctx context.Context) error) error {
	if o == nil || o.metrics == nil {
		panic("observer: not configured")
	}
	task := &implTask{
		cfg: cfg,
		fn:  fn,
	}
	return o.observe(task)
}

// RunFunc executes a function with the DefaultTaskConfig and observes its execution.
// Any timeout specified through the task configuration will be ignored by the function.
func (o *Observer) RunFunc(fn func() error) error {
	if o == nil || o.metrics == nil {
		panic("observer: not configured")
	}
	task := &implTask{
		cfg: *o.cfg.taskConfig,
		fn: func(ctx context.Context) error {
			return fn() // ignore ctx
		},
	}
	return o.observe(task)
}

// RunFuncCtx executes a function with the DefaultTaskConfig and observes its execution.
// Any timeout specified through the task configuration will be set by the context passed to fn.
func (o *Observer) RunFuncCtx(fn func(ctx context.Context) error) error {
	if o == nil || o.metrics == nil {
		panic("observer: not configured")
	}
	task := &implTask{
		cfg: *o.cfg.taskConfig,
		fn:  fn,
	}
	return o.observe(task)
}

// RunTask executes a [Task] implementation and observes its execution.
// Any timeout specified through the task configuration will be set by the context passed to task.Execute.
func (o *Observer) RunTask(task Task) error {
	if o == nil || o.metrics == nil {
		panic("observer: not configured")
	}
	t := &implTask{
		cfg: task.Config(),
		fn:  task.Execute,
	}
	return o.observe(t)
}

// observe is the internal method that observes task execution.
// This method manages the InFlight gauge for individual tasks.
func (o *Observer) observe(task *implTask) (err error) {
	o.metrics.InFlight.Inc()
	defer o.metrics.InFlight.Dec()
	return o.executeTask(task)
}

// executeTask performs the task execution logic and handles retries.
// Retry attempts are call method recursively for synchronous task handling.
// If panic occurs, the error from task.Execute() is switched for ErrPanicOccurred.
// This follows the behaviour defined by the [Task], [TaskConfig], and [Observer].
func (o *Observer) executeTask(task *implTask) error {
	var ctx = context.Background()
	if task.Config().Timeout > 0 {
		var cancel context.CancelFunc
		ctx, cancel = context.WithTimeout(ctx, task.Config().Timeout)
		defer cancel()
	}

	// Run task in closure to capture the panic
	var panicValue any
	err := func() (err error) {
		start := time.Now()
		defer func() {
			o.observeRuntime(start)
			if r := recover(); r != nil {
				panicValue = r
				err = &ErrPanicOccurred{panic: r}
			}
		}()
		err = task.Execute(ctx)
		return err
	}()

	// Handle errors
	if err != nil {
		o.metrics.Errors.Inc()
		if errors.Is(err, context.DeadlineExceeded) {
			o.metrics.TimeoutErrors.Inc()
		}

		// Handle panics
		if panicValue != nil {
			o.metrics.Panics.Inc()
			if !o.cfg.recoverPanics {
				panic(panicValue) // re-throw panic
			}
		}

		// Handle retries
		if task.Config().MaxRetries > 0 {
			cfg := task.Config()

			// Maximum retries reached
			if task.retryCount >= cfg.MaxRetries {
				return err
			} else {
				o.metrics.Retries.Inc()
			}

			// Try circuit break
			if cfg.RetryCircuitBreaker != nil {
				if cfg.RetryCircuitBreaker(err) {
					return err
				}
			}
			// Wait retry duration
			if cfg.RetryStrategy != nil {
				wait := cfg.RetryStrategy(task.retryCount)
				if wait > 0 {
					time.Sleep(wait)
				}
			}

			// Next retry attempt
			retryTask := &implTask{
				fn:         task.Execute,
				cfg:        cfg,
				retryCount: task.retryCount + 1,
			}

			// Run retry task
			err2 := o.observe(retryTask)
			if err2 != nil {
				return errors.Join(err, err2)
			} else {
				return nil // successful recursive return
			}
		}
	} else {
		o.metrics.Successes.Inc()
	}

	return err
}

// observeRuntime observes the runtime duration of the task execution.
func (o *Observer) observeRuntime(start time.Time) {
	if o.metrics.ObservedRuntimes != nil {
		o.metrics.ObservedRuntimes.Observe(time.Since(start).Seconds())
	}
}
