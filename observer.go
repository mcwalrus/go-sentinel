// Package sentinel provides reliability handling and observability monitoring for Go applications.
// It wraps task execution with Prometheus metrics, observing errors, panic occurrences, retries,
// and timeouts â€” making critical routines safe, measurable, and reliable.
package sentinel

import (
	"context"
	"errors"
	"sync"
	"time"

	"github.com/prometheus/client_golang/prometheus"
)

// ObserverConfig defines the configuration of an [Observer] instance,
// including Prometheus metrics naming and histogram bucket configuration.
type ObserverConfig struct {
	// Namespace is the Prometheus namespace for all metrics generated by this observer.
	// For example, "myapp" results in metrics like "myapp_sentinel_successes_total".
	// If empty, no namespace prefix is used.
	Namespace string

	// Subsystem is the Prometheus subsystem for all metrics generated by this observer.
	// For example, "workers" results in metrics like "workers_successes_total".
	// Defaults to "sentinel" if not specified.
	Subsystem string

	// Description is used in the help text for generated metrics to describe what type
	// of tasks are being observed. For example, "background processes" results in help
	// text like: "Number of successes from observed background processes". Defaults to
	// "tasks".
	Description string

	// BucketDurations defines the histogram buckets for task duration metrics.
	// Each recorded runtime duration is assigned within one of the specified buckets.
	// Please refer to [prometheus.HistogramOpts].Buckets for more information.
	BucketDurations []float64

	// ConstLabels are used to attach fixed labels to this metrics. By default, no labels
	// are attached. Please refer to [prometheus.Opts].ConstLabels for more information.
	ConstLabels prometheus.Labels

	// DefaultTaskConfig specifies the default [TaskConfig] for calls to [Observer.RunFunc].
	// If not specified, a basic task configuration of panic recovery without retry attempts
	// will be used.
	DefaultTaskConfig *TaskConfig
}

func DefaultConfig() ObserverConfig {
	return ObserverConfig{
		Namespace:       "",
		Subsystem:       "sentinel",
		Description:     "tasks",
		BucketDurations: []float64{0.01, 0.1, 1, 10, 100},
	}
}

// Observer monitors and measures task executions, collecting Prometheus metrics
// for successes, failures, timeouts, panics, retries, and execution durations.
// It provides methods to execute tasks with various configuration options.
type Observer struct {
	cfg     ObserverConfig
	metrics *metrics
}

// NewObserver creates a new Observer instance with the specified configuration.
// The Observer will need to be registered with a Prometheus registry to expose metrics.
// Please refer to [MustRegister] and [Register] for more information.
func NewObserver(cfg ObserverConfig) *Observer {
	if cfg.Subsystem == "" && cfg.Namespace == "" {
		cfg.Subsystem = "sentinel"
	}
	if cfg.Description == "" {
		cfg.Description = "tasks"
	}
	return &Observer{
		cfg:     cfg,
		metrics: newMetrics(cfg),
	}
}

// Register registers all Observer metrics with the provided Prometheus registry.
// Use [MustRegister] if you want the program to panic on registration conflicts.
func (o *Observer) Register(registry prometheus.Registerer) error {
	return o.metrics.Register(registry)
}

// MustRegister registers all Observer metrics with the provided Prometheus registry.
// This method panics if any metric registration failures. Use [Register] if you prefer
// to handle registration errors gracefully.
func (o *Observer) MustRegister(registry prometheus.Registerer) {
	o.metrics.MustRegister(registry)
}

// Run executes a function with the specified task configuration and observes it's execution.
// All execution metrics (duration, success/failure, retries, etc) will be automatically recorded.
func (o *Observer) Run(cfg TaskConfig, fn func(ctx context.Context) error) error {
	task := &implTask{
		cfg: cfg,
		fn:  fn,
	}
	if !task.Config().Concurrent {
		return o.observe(task)
	} else {
		go func() {
			_ = o.observe(task)
		}()
	}
	return nil
}

// RunFunc executes a simple function once without a timeout and observes it's execution.
// All execution metrics (duration, success/failure, panic, etc) will be automatically recorded.
// If a [context.DeadlineExceeded] error is returned, it is recorded as a timeout occurrence.
// Panic recovery is ignored by default and needs to be manually handled.
func (o *Observer) RunFunc(fn func() error) error {
	task := &implTask{
		cfg: o.defaultTaskConfig(),
		fn: func(ctx context.Context) error {
			return fn() // ignore ctx
		},
	}
	if !task.Config().Concurrent {
		return o.observe(task)
	} else {
		go func() {
			_ = o.observe(task)
		}()
	}
	return nil
}

// RunTask executes a [Task] implementation and observes it's execution.
// The task.Config() method determines the execution behavior (timeout, retries, concurrency, etc).
// All execution metrics (duration, success/failure, retries, etc) will be automatically recorded.
func (o *Observer) RunTask(task Task) error {
	t := &implTask{
		cfg: task.Config(),
		fn:  task.Execute,
	}
	if !task.Config().Concurrent {
		return o.observe(t)
	} else {
		go func() {
			_ = o.observe(t)
		}()
	}
	return nil
}

// defaultTaskConfig returns the default task configuration for the Observer.
func (o *Observer) defaultTaskConfig() TaskConfig {
	if o.cfg.DefaultTaskConfig != nil {
		return *o.cfg.DefaultTaskConfig
	}
	return defaultTaskConfig()
}

// observe is the internal method that observes the task execution and handles retries.
func (o *Observer) observe(task *implTask) error {
	defer func() {
		if r := recover(); r != nil {
			o.metrics.Panics.Inc()
			if !task.Config().RecoverPanics {
				panic(r)
			}
		}
	}()

	start := time.Now()
	o.metrics.InFlight.Inc()
	observeOnce := sync.Once{}

	completeTask := func() {
		observeOnce.Do(func() {
			o.metrics.InFlight.Dec()
			o.metrics.ObservedRuntimes.Observe(
				time.Since(start).Seconds(),
			)
		})
	}
	defer completeTask()

	ctx := context.Background()
	if task.Config().Timeout > 0 {
		var cancel context.CancelFunc
		ctx, cancel = context.WithTimeout(ctx, task.Config().Timeout)
		defer cancel()
	}

	// Execute the task
	err := task.Execute(ctx)
	if err != nil {
		o.metrics.Errors.Inc()
		if errors.Is(err, context.DeadlineExceeded) {
			o.metrics.TimeoutErrors.Inc()
		}

		// Handle retries
		if task.Config().MaxRetries > 0 {
			o.metrics.Retries.Inc()
			cfg := task.Config()
			completeTask()

			// Maximum retries reached
			if task.retryCount >= cfg.MaxRetries {
				return err
			}

			if cfg.RetryCurcuitBreaker != nil {
				if cfg.RetryCurcuitBreaker(err) {
					return err
				}
			}

			if cfg.RetryStrategy != nil {
				wait := cfg.RetryStrategy(task.retryCount)
				if wait > 0 {
					time.Sleep(wait)
				}
			}

			retryTask := &implTask{
				fn:         task.Execute,
				cfg:        cfg,
				retryCount: task.retryCount + 1,
			}

			// Handle task concurrency settings
			if !retryTask.Config().Concurrent {
				err2 := o.observe(retryTask)
				if err2 != nil {
					return errors.Join(err, err2)
				} else {
					// Recursive retry was successful
					return nil
				}
			} else {
				go func() {
					_ = o.observe(retryTask)
				}()
			}
		}
	} else {
		o.metrics.Successes.Inc()
	}

	return err
}
