package sentinel

import (
	"time"

	"github.com/mcwalrus/go-sentinel/circuit"
	"github.com/mcwalrus/go-sentinel/retry"
	"github.com/prometheus/client_golang/prometheus"
)

type observerConfig struct {
	namespace     string
	subsystem     string
	description   string
	buckets       []float64
	trackRetries  bool
	trackTimeouts bool
	recoverPanics bool
	taskConfig    *TaskConfig
	constLabels   prometheus.Labels
}

// ObserverOption defines a configuration option for an Observer.
// Options are provided to [NewObserver] on setting up the Observer.
type ObserverOption func(*observerConfig)

// WithNamespace sets the Prometheus namespace for all metrics generated by this observer.
// For example, "myapp" with no subsystem results in metrics like "myapp_success_total".
// If empty with subsystem, no namespace prefix is used.
//
// Example usage:
//
//	observer := sentinel.NewObserver(
//	    sentinel.WithNamespace("myapp"),
//	)
func WithNamespace(namespace string) ObserverOption {
	return func(cfg *observerConfig) {
		cfg.namespace = namespace
	}
}

// WithSubsystem sets the Prometheus subsystem for all metrics generated by this observer.
// For example, "workers" with no namespace results in metrics like "workers_success_total".
// If empty with namespace, defaults to "sentinel" if not specified.
//
// Example usage:
//
//	observer := sentinel.NewObserver(
//	    sentinel.WithSubsystem("workers"),
//	)
func WithSubsystem(subsystem string) ObserverOption {
	return func(cfg *observerConfig) {
		cfg.subsystem = subsystem
	}
}

// WithDescription sets the description used in the help text for generated metrics to
// describe what type of tasks are being observed. For example, "background processes"
// results in help text like: "Number of successes from observed background processes".
// Defaults to "tasks" to convey a generic process if not specified.
//
// Example usage:
//
//	observer := sentinel.NewObserver(
//	    sentinel.WithDescription("background processes"),
//	)
func WithDescription(description string) ObserverOption {
	return func(cfg *observerConfig) {
		cfg.description = description
	}
}

// DisablePanicRecovery disables automatic panic recovery leaving panics to propagate.
// Default observer behaviour is to recover and return panics as [ErrRecoveredPanic]
// errors. Panic occurrences will always be recorded as errors and panics in metrics
// regardless of this observer option.
//
// Example usage:
//
//	observer := sentinel.NewObserver(
//	    sentinel.PanicRecovery(false),
//	)
func PanicRecovery(recover bool) ObserverOption {
	return func(cfg *observerConfig) {
		cfg.recoverPanics = recover
	}
}

// WithHistogramMetrics enables histogram durations metrics for the Observer.
// Buckets are specified in seconds with generated buckets range between 0 and math.Inf.
// For each observed runtime of a task, it is recorded to one of the specified buckets.
// Please refer to [prometheus.HistogramOpts].Buckets for more information.
//
// Example usage:
//
//	observer := sentinel.NewObserver(
//	    sentinel.WithHistogramMetrics([]float64{0.05, 1, 5, 30, 600}),
//	)
func WithHistogramMetrics(buckets []float64) ObserverOption {
	return func(cfg *observerConfig) {
		cfg.buckets = buckets
	}
}

// WithTimeoutMetrics enables timeout-specific metrics tracking.
// When enabled, a separate "timeouts_total" metric is created to track tasks that
// failed due to context deadline exceeded. This provides visibility into timeout
// occurrences separate from general errors, allowing for better monitoring of
// timeout-related issues.
//
// Example usage:
//
//	observer := sentinel.NewObserver(
//	    sentinel.WithTimeoutMetrics(),
//	)
func WithTimeoutMetrics(config *TimeoutConfig) ObserverOption {
	return func(cfg *observerConfig) {
		if config != nil {
			cfg.trackTimeouts = true
			cfg.taskConfig.Timeout = config.Timeout
		}
	}
}

type TimeoutConfig struct {
	// Timeout is a context deadline for [Task.Execute]. By default, no timeout is applied.
	// It is the responsibility of the [Task] to handle the deadline error whenever exceeded.
	// The [Observer] records the timeout occurrences via metrics. The timeout will not be
	// respected if the observer Run* func does not pass a context.
	Timeout time.Duration
}

// WithRetryMetrics enables comprehensive retry observability metrics.
// When enabled, both "retries_total" and "failures_total" metrics are created to provide
// complete visibility into retry behavior. The "retries_total" metric tracks individual
// retry attempts, while "failures_total" tracks tasks that ultimately failed after
// exhausting all retry attempts. This provides visibility into retry effectiveness and
// distinguishes between transient failures (resolved by retries) and persistent failures.
//
// Example usage:
//
//	observer := sentinel.NewObserver(
//	    sentinel.WithRetryMetrics(),
//	)
func WithRetryMetrics(config *RetryConfig) ObserverOption {
	return func(cfg *observerConfig) {
		if config != nil {
			cfg.trackRetries = true
			cfg.taskConfig.MaxRetries = config.MaxRetries
			cfg.taskConfig.RetryStrategy = config.RetryStrategy
			cfg.taskConfig.CircuitBreaker = config.CircuitBreaker
		}
	}
}

type RetryConfig struct {
	// MaxRetries specifies the number of retry attempts for failed calls of [Task.Execute].
	// If set to zero, no retries are performed. Each retry attempt is recorded via metrics.
	// Errors returned from multiple retries are grouped by [errors.Join] as a single error.
	MaxRetries int

	// RetryStrategy is a handler to return wait durations between retry attempts. The first
	// wait duration requested by the handler will provide retryCount at 0. Subsequent retries
	// will increment retryCount. By default, no wait strategy is applied by the [Observer].
	// Use the retry package for common strategies like retry.Exponential, retry.Linear, etc.
	RetryStrategy retry.Strategy

	// CircuitBreaker is a handler that when will avoid all following retry attempts when
	// true is returned. The handler will be provided the error from the previous attempt.
	// When nil, the [Observer] will always attempt the next retry. This is useful to stop
	// retries when certain errors or conditions have occurred.
	CircuitBreaker circuit.Breaker
}

// WithConstLabels sets constant labels to exported metrics from the Observer.
// By convention, ConstLabels are not a recommended practice for Prometheus metrics.
// For more information, please refer to [prometheus.Opts].ConstLabels documentation.
//
// Example usage:
//
//	observer := sentinel.NewObserver(
//	    sentinel.WithConstLabels(prometheus.Labels{"env": "production"}),
//	)
func WithConstLabels(labels prometheus.Labels) ObserverOption {
	return func(cfg *observerConfig) {
		cfg.constLabels = labels
	}
}
